{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured output with Multimodal Agents in LangGraph"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install langchain langchain-groq langgraph langchain-anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up enviornment variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import getpass\n",
    "\n",
    "# Optional: Uncomment and set these environment variables to use LangSmith\n",
    "#os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "#os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "#os.environ['LANGCHAIN_API_KEY'] = getpass.getpass('Enter your Langchain API key: ')\n",
    "#os.environ['LANGCHAIN_PROJECT'] = getpass.getpass('Enter your Langchain project ID: ')\n",
    "os.environ['GROQ_API_KEY'] = getpass.getpass('Enter your Groq API key: ')\n",
    "os.environ['ANTHROPIC_API_KEY'] = getpass.getpass('Enter your Anthropic API key: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up the LLMs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_groq import ChatGroq\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "\n",
    "# We will set streaming=True so that we can stream tokens\n",
    "# See the streaming section for more information on this.\n",
    "llama_70b = ChatGroq(model=\"llama3-groq-70b-8192-tool-use-preview\", temperature=0.0)\n",
    "claude_haiku = ChatAnthropic(model=\"claude-3-haiku-20240307\", temperature=0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Sequence, TypedDict\n",
    "from langchain_core.pydantic_v1 import BaseModel, Field\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "\n",
    "class ImageDataPoints(BaseModel):\n",
    "    colors: Sequence[str] = Field(description=\"The colors present in the image\")\n",
    "    text: Sequence[str] = Field(description=\"The text present in the image\")\n",
    "    objects: Sequence[str] = Field(description=\"The objects present in the image\")\n",
    "    vibes: Sequence[str] = Field(description=\"The vibes present in the image\")\n",
    "\n",
    "class AgentReasoning(BaseModel):\n",
    "    reasoning: str = Field(description=\"The reasoning behind the final answer\")\n",
    "    final_answer: str = Field(description=\"The final answer of the agent\")\n",
    "\n",
    "class AgentState(TypedDict):\n",
    "    image_path: str\n",
    "    image_data: Sequence[ImageDataPoints]\n",
    "    image_poem: str\n",
    "    image_poem_reasoning: str\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Base64 helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "def encode_image(image_path):\n",
    "    with open(image_path, \"rb\") as image_file:\n",
    "        encoded_string = base64.b64encode(image_file.read())\n",
    "    return encoded_string.decode('utf-8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the Agent Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END, StateGraph, START\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(AgentState)\n",
    "\n",
    "# Define the summarize image function\n",
    "def extract_data(state: AgentState):\n",
    "    image_data = encode_image(state['image_path'])\n",
    "    messages = [\n",
    "        SystemMessage(\"You are an expert algorithm in unstructured data extraction from images.\"),\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": \"\"\"Please extract the following data points from the image:\n",
    "                - colors: the colors present in the image\n",
    "                - text: the text present in the image\n",
    "                - objects: the objects present in the image\n",
    "                - vibes: the vibes present in the image\n",
    "\n",
    "                 If any of them are not present, please fill them with an empty list.\n",
    "                \"\"\"},\n",
    "                {\"type\": \"image\", \"source\" : {\"type\": \"base64\", \"media_type\": \"image/jpeg\", \"data\": image_data}}\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    structured_claude = claude_haiku.with_structured_output(ImageDataPoints)\n",
    "\n",
    "    result = structured_claude.invoke(messages)\n",
    "\n",
    "    state['image_data'] = result\n",
    "\n",
    "    return state\n",
    "\n",
    "def generate_poem(state: AgentState):\n",
    "    messages = [\n",
    "        SystemMessage(\"You are an expert in generating poems.\"),\n",
    "        HumanMessage(\n",
    "            content=[\n",
    "                {\"type\": \"text\", \"text\": f\"\"\"\n",
    "                Please generate a haiku poem based on the extracted data points from the image.\n",
    "                The extracted data points are:\n",
    "                    - Colors: {state['image_data'].colors}\n",
    "                    - Text: {state['image_data'].text}\n",
    "                    - Objects: {state['image_data'].objects}\n",
    "                    - Vibes: {state['image_data'].vibes}\n",
    "\n",
    "                Reason about the extracted data points first, take your time. Once you have a clear understanding, generate an elegant, well crafted, and meaningful haiku poem.\n",
    "                \"\"\"}\n",
    "            ]\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    structured_llama = llama_70b.with_structured_output(AgentReasoning)\n",
    "\n",
    "    result = structured_llama.invoke(messages)\n",
    "\n",
    "    state['image_poem'] = result.final_answer\n",
    "    state['image_poem_reasoning'] = result.reasoning\n",
    "\n",
    "    return state\n",
    "\n",
    "workflow.add_node(\"extract_data\", extract_data)\n",
    "workflow.add_node(\"generate_poem\", generate_poem)\n",
    "\n",
    "workflow.add_edge(START, \"extract_data\")\n",
    "workflow.add_edge(\"extract_data\", \"generate_poem\")\n",
    "workflow.add_edge(\"generate_poem\", END)\n",
    "\n",
    "\n",
    "# Finally, we compile it!\n",
    "# This compiles it into a LangChain Runnable,\n",
    "# meaning you can use it as you would any other runnable\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(app.get_graph(xray=True).draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test on one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the first image\n",
    "import os\n",
    "\n",
    "image_path = os.path.join(os.getcwd(), \"images/18564-36081-51951.jpg\")\n",
    "inputs = {\"image_path\": image_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the image\n",
    "display(Image(filename=inputs[\"image_path\"], width=200))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for output in app.stream(inputs):\n",
    "    # stream() yields dictionaries with output keyed by node name\n",
    "    for key, value in output.items():\n",
    "        print(f\"Output from node '{key}':\")\n",
    "        print(\"---\")\n",
    "        print(value)\n",
    "    print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling: Test on multiple images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run it on all images in the directory\n",
    "import os\n",
    "\n",
    "image_dir = os.path.join(os.getcwd(), \"images\")\n",
    "image_files = os.listdir(image_dir)\n",
    "\n",
    "results=[]\n",
    "for image_file in image_files:\n",
    "    inputs = {\"image_path\": os.path.join(image_dir, image_file)}\n",
    "\n",
    "    # Display the image\n",
    "    display(Image(filename=inputs[\"image_path\"], width=200))\n",
    "    for output in app.stream(inputs):\n",
    "        # stream() yields dictionaries with output keyed by node name\n",
    "        for key, value in output.items():\n",
    "            print(f\"Output from node '{key}':\")\n",
    "            print(\"---\")\n",
    "            print(value)\n",
    "            if key == \"generate_poem\":\n",
    "                results.append({value['image_path']: [value['image_poem'], value['image_poem_reasoning'], value['image_data']]})\n",
    "        print(\"\\n---\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print()\n",
    "for result in results:\n",
    "    print(f\"Image: {list(result.keys())[0]}\")\n",
    "    print(\"=\"*len(f\"Image: {list(result.keys())[0]}\"))\n",
    "    print(f\"Poem: {list(result.values())[0][0]}\")\n",
    "    print(\"+\" * 50)\n",
    "    print(f\"Reasoning: {list(result.values())[0][1]}\")\n",
    "    print(\"+\" * 50)\n",
    "    print(f\"Data: {list(result.values())[0][2]}\")\n",
    "    print(\"=\"*len(f\"Image: {list(result.keys())[0]}\"))\n",
    "    print()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "art-evals",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
